{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googletrans import Translator\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "import tkinter as tk\n",
    "from tkinter import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python package Tkinter to develop a GUI (Graphical User Interface). Identifying the GUI screen's size with.geometry() and the title with .title().\n",
    "Setting the variables 'title_text' and'summary_text' that are replaces for text widgets with 'None'. In Tkinter, text widgets are features that let users to display and control text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tkinter window\n",
    "top = tk.Tk()\n",
    "top.geometry('680x680')\n",
    "top.title('News Article Summary')\n",
    "\n",
    "# Define global variables for text widgets\n",
    "title_text = None\n",
    "summary_text = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will add a scale to the screen layout for users to select the number of sentences for the summary from 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Scale widget to select the number of sentences for the summary\n",
    "num_sentences_label = Label(top, text='Select number of sentences for summary:', font=('Arial', 12))\n",
    "num_sentences_label.pack()\n",
    "\n",
    "num_sentences_scale = Scale(top, from_=1, to=3, orient=HORIZONTAL)\n",
    "num_sentences_scale.pack()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the words creating a function to preprocess the text. To lower the text using '.lower()'' and to remove non-alphanumeric characters and extra spaces using regular expression 're' this will help us to remove noise from the text. Tokenizing and analyzing text using natural language processing. To identify if it is a stop word for example the common words like is, the, etc. using lemmatizing which will iterate through each character in the text and extract it's lemma. To combine the lemmatized tokens into a single string which is separated by whitespace using join function this will make the text ready for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphanumeric characters and extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the summary from the given text creating a function with user-selected number of sentences. Using parser to create a plaintext parser object using the provided text by giving the tokenizer as english which indicates that the provided text is expected to be english. Setting up a summariser using Latent Semantic Analysis (LSA) it is technique used for summarising textual data and reducing its size. Using 'summarizer’ we will generate specified number of sentences from the given text. At last, the code will join each elements of the summary and then the sentences will be separated by a whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate summary\n",
    "def generate_summary(text, num_sentences):\n",
    "    # Initialize parser and tokenizer\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer('english'))\n",
    "    summarizer = LsaSummarizer()\n",
    "    # Generate summary with the specified number of sentences\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return ' '.join(str(sentence) for sentence in summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function will detect the language of the given text. Then to perform text translation task we will use googletrans librarly to generate a 'Translator()' object. Then using Translator object '.detect()' method to identify the language of the given text. The identified language code will be gathered with '.lang'. The function returns the language code for the identified language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    translator = Translator()\n",
    "    lang = translator.detect(text).lang\n",
    "    return lang"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using googletrans library to translate the input text to the target language which is English. the translated content can be available by using the ‘text' property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate text\n",
    "def translate_text(text, target_language):\n",
    "    translator = Translator()\n",
    "    translated_text = translator.translate(text, dest=target_language).text\n",
    "    return translated_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes text content from a provided URL. It sends an HTTP request to the URL and uses BeautifulSoup to check the HTML response. It joins text content from all paragraph tags in HTML into one big string. Finally, it provides the extracted text content as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch content from URL\n",
    "def fetch_url_content(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    article_text = ' '.join([p.get_text() for p in paragraphs])\n",
    "    return article_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing a function that shows the news article's summary the code takes the text, detects it and translates it in English, and generates the summary after the user chooses the \"url\" option and enters the news article's URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results():\n",
    "    global title_text, summary_text, author_text\n",
    "    option = choice_var.get()\n",
    "    if option == 2:\n",
    "        url = url_entry.get()\n",
    "        num_sentences = num_sentences_scale.get()  # Get the selected number of sentences\n",
    "        if url.strip() == '':\n",
    "            return  # Do nothing if the input URL is empty\n",
    "\n",
    "        # Fetch content from the URL\n",
    "        article_text = fetch_url_content(url)\n",
    "\n",
    "        # Preprocess and generate summary\n",
    "        summary = generate_summary(article_text, num_sentences)  # Pass the selected number of sentences\n",
    "        translated_summary = translate_text(summary, 'en')\n",
    "\n",
    "        clear_results()\n",
    "\n",
    "        # Display new results\n",
    "        title_label.config(text='Title: ')\n",
    "        title_text.config(state='normal')\n",
    "        title_text.delete('1.0', END)\n",
    "        title_text.insert('1.0', 'Title from URL')\n",
    "        title_text.config(state='disabled')\n",
    "\n",
    "        summary_label.config(text='Summary: ')\n",
    "        summary_text.config(state='normal')\n",
    "        summary_text.delete('1.0', END)\n",
    "        summary_text.insert('1.0', translated_summary)\n",
    "        summary_text.config(state='disabled')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a function for clearly removing previous results from the graphical user interface. Besides allowing users to enter the URL of a news story, the mainloop loop executes the GUI. The GUI will be updated as per the summary displayed in the display result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear results\n",
    "def clear_results():\n",
    "    global title_text, summary_text, author_text\n",
    "    title_text.config(state='normal')\n",
    "    title_text.delete('1.0', END)\n",
    "    title_text.config(state='disabled')\n",
    "\n",
    "    summary_text.config(state='normal')\n",
    "    summary_text.delete('1.0', END)\n",
    "    summary_text.config(state='disabled')\n",
    "\n",
    "    author_text.config(state='normal')\n",
    "    author_text.delete('1.0', END)\n",
    "    author_text.config(state='disabled')\n",
    "\n",
    "choice_var = IntVar()\n",
    "\n",
    "\n",
    "url_radio = Radiobutton(top, text='URL', variable=choice_var, value=2)\n",
    "url_radio.pack()\n",
    "\n",
    "url_label = Label(top, text='Enter URL:', font=('Arial', 12))\n",
    "url_label.pack()\n",
    "\n",
    "url_entry = Entry(top, width=50)\n",
    "url_entry.pack()\n",
    "\n",
    "# Display button\n",
    "display_button = Button(top, text='Display', command=display_results)\n",
    "display_button.pack()\n",
    "\n",
    "# Widgets for displaying results\n",
    "title_label = Label(top, text=\"\", font=('Arial', 12, 'bold'))\n",
    "title_label.pack()\n",
    "\n",
    "title_text = Text(top, height=2, width=80, wrap='word')\n",
    "title_text.pack()\n",
    "\n",
    "summary_label = Label(top, text=\"\", font=('Arial', 12, 'bold'))\n",
    "summary_label.pack()\n",
    "\n",
    "summary_text = Text(top, height=15, width=80, wrap='word')\n",
    "summary_text.pack()\n",
    "\n",
    "author_label = Label(top, text=\"\", font=('Arial', 12, 'bold'))\n",
    "author_label.pack()\n",
    "\n",
    "author_text = Text(top, height=1, width=80, wrap='word')\n",
    "author_text.pack()\n",
    "\n",
    "top.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
